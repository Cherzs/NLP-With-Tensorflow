# -*- coding: utf-8 -*-
"""NLP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MTYKqoa7RrWQ33JLSvuk6jCO92v2Tm6q

Nama  : Muhammad Zhafran Ghaly

ID    : m183x0348


Kelas : M02


Divisi: Machine Learning and Front-End
"""

import pandas as pd
import numpy as np
import tensorflow as tf
from tensorflow import keras
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.layers import LSTM,Dense,Embedding,Dropout
from tensorflow.keras.models import Sequential
from sklearn.model_selection import train_test_split

!pip install -q kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

!kaggle datasets download -d muhammadghazimuharam/indonesiafalsenews

!unzip '/content/indonesiafalsenews.zip'

df = pd.read_csv('Data_latih.csv')
df.head(10)

d = { 0 :'hoax' , 1 :'real'}
df['label'] = df['label'].map(d).fillna(df['label'])

df.label.value_counts()

category = pd.get_dummies(df.label)
df_two = pd.concat([df, category], axis=1)
df_two = df_two.drop(columns=['label'])
df_two.head(5)

df_two.columns

df_1 = df_two['judul'].values
motive = df_two[['hoax', 'real']].values

X_train, X_test, y_train, y_test = train_test_split(
    df_1, 
    motive, 
    test_size = 0.2)

tokenizer = Tokenizer(num_words=5000, oov_token='<UNK>')
tokenizer.fit_on_texts(X_train)
tokenizer.fit_on_texts(X_test)

sekuens_train = tokenizer.texts_to_sequences(X_train)
sekuens_test = tokenizer.texts_to_sequences(X_test)

padded_train = pad_sequences(sekuens_train, maxlen = 20, truncating = 'post')
padded_test = pad_sequences(sekuens_test, maxlen = 20, truncating = 'post')
print(padded_test.shape)

padded_train

padded_test

model = tf.keras.Sequential([
    tf.keras.layers.Embedding(input_dim = 5000, output_dim = 16, input_length = 20),
    tf.keras.layers.LSTM(64),
    tf.keras.layers.Dense(16, activation = 'relu'),
    tf.keras.layers.Dropout(0.5),
    tf.keras.layers.Dense(2, activation = 'softmax')
])

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])
model.summary()

class Callbackhx(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        if(logs.get('accuracy') >= 0.85):
            print("\nReached %2.2f%% accuracy, training has been stop" %(logs.get('accuracy')*100))
            self.model.stop_training = True

callbacks = Callbackhx()

num_epoch = 50
historymod = model.fit(
    padded_train, 
    y_train, 
    epochs = num_epoch, 
    validation_data = (padded_test, y_test),
    verbose = 2,
    callbacks = [callbacks]
)